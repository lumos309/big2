{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Soft Actor Critic Demystified</h1>\n",
    "<h4> By Vaishak Kumar </h4>\n",
    "<br>\n",
    "<a href=\"https://arxiv.org/pdf/1801.01290.pdf\">Original Paper</a>\n",
    "<br> \n",
    "<a href=\"https://github.com/higgsfield/RL-Adventure-2\">Adapted from higgsfield's implementation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from big2Game import vectorizedBig2Games\n",
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Auxilliary Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizedActions(gym.ActionWrapper):\n",
    "    def action(self, action):\n",
    "        low  = self.action_space.low\n",
    "        high = self.action_space.high\n",
    "        \n",
    "        action = low + (action + 1.0) * 0.5 * (high - low)\n",
    "        action = np.clip(action, low, high)\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def _reverse_action(self, action):\n",
    "        low  = self.action_space.low\n",
    "        high = self.action_space.highnum_inputs, num_actions, \n",
    "        \n",
    "        action = 2 * (action - low) / (high - low) - 1\n",
    "        action = np.clip(action, low, high)\n",
    "        \n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "def plot_win_ratios(frame_idx, win_ratio):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('episode %s. win percentage: %s' % (frame_idx, win_ratio[-1]))\n",
    "    plt.plot(win_ratio)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Network Definitions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, init_w=3e-3):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(state_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class SoftQNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(SoftQNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs + num_actions, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], 1)\n",
    "        # print('num inputs0,')\n",
    "        # print('state shape', state.shape, 'action shape', action.shape)\n",
    "        # print('x.shape', x.shape)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3, log_std_min=-20, log_std_max=2):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        \n",
    "        self.log_std_min = log_std_min\n",
    "        self.log_std_max = log_std_max\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.mean_linear = nn.Linear(hidden_size, num_actions)\n",
    "        self.mean_linear.weight.data.uniform_(-init_w, init_w)\n",
    "        self.mean_linear.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "        self.log_std_linear = nn.Linear(hidden_size, num_actions)\n",
    "        self.log_std_linear.weight.data.uniform_(-init_w, init_w)\n",
    "        self.log_std_linear.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        \n",
    "        mean    = self.mean_linear(x)\n",
    "        log_std = self.log_std_linear(x)\n",
    "        log_std = torch.clamp(log_std, self.log_std_min, self.log_std_max)\n",
    "        \n",
    "        return mean, log_std\n",
    "    \n",
    "    def evaluate(self, state, epsilon=1e-6):\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        \n",
    "        normal = Normal(0, 1)\n",
    "        z      = normal.sample()\n",
    "        action = torch.tanh(mean+ std*z.to(device))\n",
    "        log_prob = Normal(mean, std).log_prob(mean+ std*z.to(device)) - torch.log(1 - action.pow(2) + epsilon)\n",
    "        return action, log_prob, z, mean, log_std\n",
    "        \n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        \n",
    "        normal = Normal(0, 1)\n",
    "        z      = normal.sample().to(device)\n",
    "        action = torch.tanh(mean + std*z)\n",
    "        \n",
    "        action  = action.cpu()#.detach().cpu().numpy()\n",
    "        return action[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Update Function </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(batch_size,gamma=0.99,soft_tau=1e-2,):\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "    state      = torch.FloatTensor(state).to(device)\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    action     = torch.FloatTensor(action).to(device)\n",
    "    reward     = torch.FloatTensor(reward).unsqueeze(1).to(device)\n",
    "    done       = torch.FloatTensor(np.float32(done)).unsqueeze(1).to(device)\n",
    "\n",
    "    predicted_q_value1 = soft_q_net1(state, action)\n",
    "    predicted_q_value2 = soft_q_net2(state, action)\n",
    "    predicted_value    = value_net(state)\n",
    "    new_action, log_prob, epsilon, mean, log_std = policy_net.evaluate(state)\n",
    "\n",
    "    \n",
    "    \n",
    "# Training Q Function\n",
    "    target_value = target_value_net(next_state)\n",
    "    target_q_value = reward + (1 - done) * gamma * target_value\n",
    "    q_value_loss1 = soft_q_criterion1(predicted_q_value1, target_q_value.detach())\n",
    "    q_value_loss2 = soft_q_criterion2(predicted_q_value2, target_q_value.detach())\n",
    "\n",
    "\n",
    "    soft_q_optimizer1.zero_grad()\n",
    "    q_value_loss1.backward()\n",
    "    soft_q_optimizer1.step()\n",
    "    soft_q_optimizer2.zero_grad()\n",
    "    q_value_loss2.backward()\n",
    "    soft_q_optimizer2.step()    \n",
    "# Training Value Function\n",
    "    predicted_new_q_value = torch.min(soft_q_net1(state, new_action),soft_q_net2(state, new_action))\n",
    "    target_value_func = predicted_new_q_value - log_prob\n",
    "    value_loss = value_criterion(predicted_value, target_value_func.detach())\n",
    "\n",
    "    \n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward()\n",
    "    value_optimizer.step()\n",
    "# Training Policy Function\n",
    "    policy_loss = (log_prob - predicted_new_q_value).mean()\n",
    "\n",
    "    policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "    \n",
    "    \n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Initializations </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "nGames = 1\n",
    "env = vectorizedBig2Games(nGames)\n",
    "\n",
    "action_dim = 1695 # env.action_space.shape[0]\n",
    "state_dim  = 412 #env.observation_space.shape[0]\n",
    "hidden_dim = 256\n",
    "\n",
    "value_net        = ValueNetwork(state_dim, hidden_dim).to(device)\n",
    "target_value_net = ValueNetwork(state_dim, hidden_dim).to(device)\n",
    "\n",
    "soft_q_net1 = SoftQNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "soft_q_net2 = SoftQNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "\n",
    "\n",
    "for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "    \n",
    "\n",
    "value_criterion  = nn.MSELoss()\n",
    "soft_q_criterion1 = nn.MSELoss()\n",
    "soft_q_criterion2 = nn.MSELoss()\n",
    "\n",
    "value_lr  = 3e-4\n",
    "soft_q_lr = 3e-4\n",
    "policy_lr = 3e-4\n",
    "\n",
    "value_optimizer  = optim.Adam(value_net.parameters(), lr=value_lr)\n",
    "soft_q_optimizer1 = optim.Adam(soft_q_net1.parameters(), lr=soft_q_lr)\n",
    "soft_q_optimizer2 = optim.Adam(soft_q_net2.parameters(), lr=soft_q_lr)\n",
    "policy_optimizer = optim.Adam(policy_net.parameters(), lr=policy_lr)\n",
    "\n",
    "\n",
    "replay_buffer_size = 1000000\n",
    "replay_buffer = ReplayBuffer(replay_buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames  = 40000\n",
    "max_steps   = 500\n",
    "frame_idx   = 0\n",
    "rewards     = []\n",
    "batch_size  = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from math import inf\n",
    "episode = 0\n",
    "game_won, game_lost = 0, 0  \n",
    "win_ratios = []\n",
    "while frame_idx < max_frames:\n",
    "    [playerTurn, state, availableActions] = env.getCurrStates()\n",
    "    episode_reward = 0\n",
    "    is_game_over = False\n",
    "    for step in range(max_steps):\n",
    "        \n",
    "        ## Run action for player 1\n",
    "        player1_reward = 0\n",
    "        # if frame_idx >1000:\n",
    "        [playerTurn, state, availableActions] = env.getCurrStates()\n",
    "        action = policy_net.get_action(state).detach().numpy()[0]\n",
    "        action = np.add(action, availableActions)\n",
    "        action = action.argmax()\n",
    "\n",
    "        reward, done, next_state = env.step([action])  \n",
    "        # print('action taken', action)\n",
    "\n",
    "        player1_reward = np.array(reward).squeeze()[0]\n",
    "        # print('reward', player1_reward)\n",
    "\n",
    "        # else:\n",
    "        #     # action = env.action_space.sample()\n",
    "        #     action = random.randint(0,action_dim-1)\n",
    "          \n",
    "        #     while availableActions[0,0,action] == -inf:\n",
    "        #         action =  random.randint(0,action_dim-1)\n",
    "                \n",
    "        #     # print('action taken random', action)\n",
    "        #     # print('availableActions', availableActions[0,0,action])\n",
    "        #     reward, done, next_state = env.step([action])\n",
    "\n",
    "        #     player1_reward += np.array(reward).squeeze()[0]\n",
    "        #     # print('reward', player1_reward)\n",
    "        # print('episode', episode, 'frame_idx', frame_idx, 'a', action, ', r ', player1_reward)\n",
    "    \n",
    "    \n",
    "        # print('pushing to buffer', state, action, reward, next_state, done)\n",
    "        # print('pushing to buffer', np.array(state.shape), action,player1_reward, np.array(next_state).shape, np.array(done).shape)\n",
    "        # pushing to buffer [  1   1 412] () (1,) (1, 4) (1, 3)\n",
    "        # print('next_state', next_state)\n",
    "        state = state.squeeze()\n",
    "        next_state = np.array(next_state).squeeze()\n",
    "        action = [action]\n",
    "        done = done[0]\n",
    "        # print('pushing to buffer after shape', np.array(state).shape, action,player1_reward, np.array(next_state).shape, done)\n",
    "\n",
    "\n",
    "        # try one hot encoding the action space\n",
    "        action_one_hot = np.zeros(action_dim)\n",
    "        action_one_hot[action] = 1\n",
    "        action = action_one_hot\n",
    "        # print('one hot encode action', action)\n",
    "        # action = np.zeros(action_dim)[action] = 1 \n",
    "        replay_buffer.push(state, action, player1_reward, next_state, done)\n",
    "        is_game_over = is_game_over or done\n",
    "\n",
    "       \n",
    "        # pushing to buffer [ 0.29733867 -0.95477208 -0.69822459] [-1.6809958] -1.6628393972491333 [ 0.21450876 -0.97672206 -1.71430365] False\n",
    "        # pushing to buffer after shape [412] [7] 0.0 (1, 1, 412) (1,)\n",
    "\n",
    "        ### Run action for player 2 - 4\n",
    "        for player in range(1, 3):\n",
    "            [playerTurn, state, availableActions] = env.getCurrStates()\n",
    "            action = policy_net.get_action(state).detach().numpy()[0]\n",
    "            action1 = action\n",
    "            action = np.add(action, availableActions)\n",
    "            action2 = action\n",
    "            action = action[0,0,:].argmax()\n",
    "            # print('action taken opponent', action)\n",
    "            reward, done, next_state = env.step([action])   \n",
    "            is_game_over = is_game_over or done[0]\n",
    "            if (done[0]):\n",
    "                player1_reward = np.array(reward).squeeze()[0]\n",
    "                break      \n",
    "\n",
    "        if (is_game_over):\n",
    "            if (player1_reward > 0):\n",
    "                game_won += 1\n",
    "            else:\n",
    "                game_lost += 1 \n",
    "        \n",
    "        state = next_state\n",
    "        episode_reward += player1_reward\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if len(replay_buffer) > batch_size:\n",
    "            update(batch_size)\n",
    "            # print('updating params')\n",
    "        \n",
    "        # if frame_idx % 500 == 0:\n",
    "        #     plot(frame_idx, rewards)\n",
    "        \n",
    "        if is_game_over:\n",
    "            print('episode : ', episode, game_won, game_lost)\n",
    "\n",
    "            break\n",
    "    episode += 1    \n",
    "    rewards.append(episode_reward)\n",
    "\n",
    "    if (episode > 12):\n",
    "        win_ratios.append( game_won/episode)\n",
    "        plot_win_ratios(episode, win_ratios)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Visualize Trained Algorithm </h2> - <a href=\"http://mckinziebrandon.me/TensorflowNotebooks/2016/12/21/openai.html\">source</a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    #plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    display(anim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_ckp():\n",
    "    checkpoint_path = 'checkpoint.pt'\n",
    "    checkpoint = {\n",
    "       'soft_q_net1': soft_q_net1.state_dict(),\n",
    "       'soft_q_net2': soft_q_net2.state_dict(),\n",
    "       'policy_net':   policy_net.state_dict(),\n",
    "       'value_net':   value_net.state_dict(),\n",
    "       'target_value_net': target_value_net.state_dict(),\n",
    "       \n",
    "       'value_optimizer': value_optimizer.state_dict(),\n",
    "       'soft_q_optimizer1': soft_q_optimizer1.state_dict(),\n",
    "        'soft_q_optimizer2': soft_q_optimizer2.state_dict(),\n",
    "        'policy_optimizer': policy_optimizer.state_dict(),\n",
    "    \n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    \n",
    "def load_ckp(soft_q_net1, soft_q_net2, policy_net, value_net, target_value_net, value_optimizer, soft_q_optimizer1, soft_q_optimizer2, policy_optimizer):\n",
    "    checkpoint_path = 'checkpoint.pt'\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    \n",
    "    soft_q_net1.load_state_dict(checkpoint['soft_q_net1'])\n",
    "    soft_q_net2.load_state_dict(checkpoint['soft_q_net2'])\n",
    "    policy_net.load_state_dict(checkpoint['policy_net'])\n",
    "    value_net.load_state_dict(checkpoint['value_net'])\n",
    "    target_value_net.load_state_dict(checkpoint['target_value_net'])\n",
    "\n",
    "    value_optimizer.load_state_dict(checkpoint['value_optimizer'])\n",
    "    soft_q_optimizer1.load_state_dict(checkpoint['soft_q_optimizer1'])\n",
    "    soft_q_optimizer2.load_state_dict(checkpoint['soft_q_optimizer2'])\n",
    "    policy_optimizer.load_state_dict(checkpoint['policy_optimizer'])\n",
    "    \n",
    "    return soft_q_net1, soft_q_net2, policy_net, value_net, target_value_net, value_optimizer, soft_q_optimizer1, soft_q_optimizer2, policy_optimizer\n",
    "\n",
    "save_ckp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yosua/anaconda3/envs/fp_cs5446/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/yosua/anaconda3/envs/fp_cs5446/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yosua/Documents/Projects/big2/big2Game.py\", line 531, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/yosua/anaconda3/envs/fp_cs5446/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/yosua/anaconda3/envs/fp_cs5446/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/yosua/anaconda3/envs/fp_cs5446/lib/python3.7/multiprocessing/connection.py\", line 383, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ImageData' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8068/3598216372.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Render into buffer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fp_cs5446/lib/python3.7/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fp_cs5446/lib/python3.7/site-packages/gym/envs/classic_control/pendulum.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgtrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_u\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fp_cs5446/lib/python3.7/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_buffer_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_color_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;31m# In https://github.com/openai/gym-http-api/issues/2, we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m# discovered that someone using Xmonad on Arch was having\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageData' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Pendulum-v0\")\n",
    "\n",
    "# Run a demo of the environment\n",
    "state = env.reset()\n",
    "cum_reward = 0\n",
    "frames = []\n",
    "for t in range(50000):\n",
    "    # Render into buffer. \n",
    "    frames.append(env.render(mode = 'rgb_array'))\n",
    "    action = policy_net.get_action(state)\n",
    "    state, reward, done, info = env.step(action.detach())\n",
    "    if done:\n",
    "        break\n",
    "env.close()\n",
    "display_frames_as_gif(frames)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
