replay buffer 1000000 [412] 1695
shape (1000000, 412) (1000000, 412)
---------------------MINIBATCH 1 -----------------
appending prev_obs with size: 0
running game for steps:  4
observation:  [[0 0 1 ... 1 0 0]
 [0 0 1 ... 1 0 0]
 [0 0 1 ... 1 0 0]]
action shape torch.Size([1, 3, 1695])
log probs 1  tensor([[[12.7404, 12.7710, 12.8929,  ..., 12.7378,  3.1225,  5.9427],
         [12.7277, 12.8744, 11.3178,  ..., 12.8920,  2.7597,  5.0362],
         [12.8831, 12.8690, 12.6667,  ..., 12.7378,  3.0617,  5.8949]]],
       grad_fn=<SubBackward0>) tensor([[[189.2236,  43.9935, -67.7723,  ..., -13.4994, -65.5611, -57.9628],
         [189.2255,  43.9947, -67.7752,  ..., -13.5002, -30.9390, -60.8945],
         [189.2243,  43.9947, -67.7733,  ..., -13.4994, -43.3625, -59.3912]]])
log probs 2  tensor([[[nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SubBackward0>) tensor([[[189.2236,  43.9935, -67.7723,  ..., -13.4994, -65.5611, -57.9628],
         [189.2255,  43.9947, -67.7752,  ..., -13.5002, -30.9390, -60.8945],
         [189.2243,  43.9947, -67.7733,  ..., -13.4994, -43.3625, -59.3912]]])
log probs 3  tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SumBackward1>) tensor([[[189.2236,  43.9935, -67.7723,  ..., -13.4994, -65.5611, -57.9628],
         [189.2255,  43.9947, -67.7752,  ..., -13.5002, -30.9390, -60.8945],
         [189.2243,  43.9947, -67.7733,  ..., -13.4994, -43.3625, -59.3912]]])
possible_actions_probablities [[189.22358704  43.99349976 -67.77232361 ...         -inf         -inf
  -57.96284485]
 [189.22549438  43.99470139 -67.77518463 ...         -inf         -inf
  -60.89453888]
 [189.22425842  43.99474335 -67.77332306 ...         -inf         -inf
  -59.39118195]]
actions taken:  [7 7 7]
rewards (array([0., 0., 0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0.]))
observation:  [[1 0 0 ... 1 0 0]
 [1 0 0 ... 1 0 0]
 [1 0 0 ... 1 0 0]]
action shape torch.Size([1, 3, 1695])
log probs 1  tensor([[[ 4.1954, 12.0227, 12.3907,  ..., 12.3785,  1.8094,  5.9051],
         [ 4.0774, 12.8478, 12.5728,  ..., 12.8258,  2.1816,  5.8332],
         [ 4.3342, 12.8457, 12.8215,  ..., 12.7855,  2.5282,  5.4986]]],
       grad_fn=<SubBackward0>) tensor([[[ 129.8416,  -11.2206,  -75.3321,  ...,   16.5994, -125.0741,
           -58.5960],
         [ 118.5550,  -11.2234,  -75.3317,  ...,   16.6005, -106.4292,
           -59.4952],
         [ 123.2948,  -11.2223,  -75.3310,  ...,   16.6003,  -48.8839,
           -57.1155]]])
log probs 2  tensor([[[nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SubBackward0>) tensor([[[ 129.8416,  -11.2206,  -75.3321,  ...,   16.5994, -125.0741,
           -58.5960],
         [ 118.5550,  -11.2234,  -75.3317,  ...,   16.6005, -106.4292,
           -59.4952],
         [ 123.2948,  -11.2223,  -75.3310,  ...,   16.6003,  -48.8839,
           -57.1155]]])
log probs 3  tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SumBackward1>) tensor([[[ 129.8416,  -11.2206,  -75.3321,  ...,   16.5994, -125.0741,
           -58.5960],
         [ 118.5550,  -11.2234,  -75.3317,  ...,   16.6005, -106.4292,
           -59.4952],
         [ 123.2948,  -11.2223,  -75.3310,  ...,   16.6003,  -48.8839,
           -57.1155]]])
possible_actions_probablities [[        -inf         -inf         -inf ...         -inf         -inf
  -58.5959816 ]
 [        -inf         -inf         -inf ...         -inf         -inf
  -59.49521637]
 [        -inf         -inf         -inf ...         -inf         -inf
  -57.11551666]]
actions taken:  [7 7 7]
rewards (array([0., 0., 0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0.]))
observation:  [[1 0 0 ... 1 0 0]
 [1 0 0 ... 1 0 0]
 [1 0 0 ... 1 0 0]]
action shape torch.Size([1, 3, 1695])
log probs 1  tensor([[[12.8404, 12.8806, 12.2102,  ..., 12.7567, 11.2576,  5.0352],
         [12.8544, 12.7497, 12.2233,  ..., 12.7537, 12.8959,  5.0738],
         [11.5896, 12.8953, 12.4835,  ..., 12.8954, 12.8965,  5.0650]]],
       grad_fn=<SubBackward0>) tensor([[[ 151.2955,   52.7692,  -45.3901,  ...,   37.7455, -109.6624,
           -18.4791],
         [ 151.2956,   52.7698,  -45.3902,  ...,   37.7456, -109.6594,
           -19.0140],
         [ 151.2988,   52.7688,  -45.3937,  ...,   37.7446, -109.6593,
           -18.8686]]])
log probs 2  tensor([[[nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SubBackward0>) tensor([[[ 151.2955,   52.7692,  -45.3901,  ...,   37.7455, -109.6624,
           -18.4791],
         [ 151.2956,   52.7698,  -45.3902,  ...,   37.7456, -109.6594,
           -19.0140],
         [ 151.2988,   52.7688,  -45.3937,  ...,   37.7446, -109.6593,
           -18.8686]]])
log probs 3  tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SumBackward1>) tensor([[[ 151.2955,   52.7692,  -45.3901,  ...,   37.7455, -109.6624,
           -18.4791],
         [ 151.2956,   52.7698,  -45.3902,  ...,   37.7456, -109.6594,
           -19.0140],
         [ 151.2988,   52.7688,  -45.3937,  ...,   37.7446, -109.6593,
           -18.8686]]])
possible_actions_probablities [[        -inf         -inf         -inf ...         -inf         -inf
  -18.47914124]
 [        -inf         -inf         -inf ...         -inf         -inf
  -19.0140419 ]
 [        -inf         -inf         -inf ...         -inf         -inf
  -18.8686409 ]]
actions taken:  [11 11 11]
rewards (array([0., 0., 0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0.]))
observation:  [[0 1 0 ... 1 0 0]
 [0 1 0 ... 1 0 0]
 [0 1 0 ... 1 0 0]]
action shape torch.Size([1, 3, 1695])
log probs 1  tensor([[[ 3.8180, 12.4936, 12.3789,  ...,  3.8015,  2.5042, 12.2200],
         [ 4.0710, 11.6016, 12.7459,  ...,  4.0389,  2.4394, 12.6568],
         [ 3.9030, 12.4801, 12.7134,  ...,  2.6559,  2.5539, 12.5076]]],
       grad_fn=<SubBackward0>) tensor([[[ 29.4028,  61.0342,  -0.2289,  ...,  80.1373, -25.4155, -11.6297],
         [ 14.4923,  61.0329,  -0.2315,  ...,  67.3575,  16.3335, -11.6289],
         [ 28.5056,  61.0341,  -0.2296,  ...,  52.5243,  -8.8461, -11.6262]]])
log probs 2  tensor([[[    nan,     nan, 12.4327,  ...,     nan,     nan,     nan],
         [    nan,     nan, 12.8010,  ...,     nan,     nan,     nan],
         [    nan,     nan, 12.7676,  ...,     nan,     nan,     nan]]],
       grad_fn=<SubBackward0>) tensor([[[ 29.4028,  61.0342,  -0.2289,  ...,  80.1373, -25.4155, -11.6297],
         [ 14.4923,  61.0329,  -0.2315,  ...,  67.3575,  16.3335, -11.6289],
         [ 28.5056,  61.0341,  -0.2296,  ...,  52.5243,  -8.8461, -11.6262]]])
log probs 3  tensor([[[    nan,     nan, 38.0012,  ...,     nan,     nan,     nan]]],
       grad_fn=<SumBackward1>) tensor([[[ 29.4028,  61.0342,  -0.2289,  ...,  80.1373, -25.4155, -11.6297],
         [ 14.4923,  61.0329,  -0.2315,  ...,  67.3575,  16.3335, -11.6289],
         [ 28.5056,  61.0341,  -0.2296,  ...,  52.5243,  -8.8461, -11.6262]]])
possible_actions_probablities [[        -inf         -inf         -inf ...         -inf         -inf
  -11.62967777]
 [        -inf         -inf         -inf ...         -inf         -inf
  -11.62887955]
 [        -inf         -inf         -inf ...         -inf         -inf
  -11.62621117]]
actions taken:  [11 11 11]
rewards (array([0., 0., 0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0.]))
end length:  0
before cutting:  (4, 3, 412)
after cutting:  (4, 3, 412)
minibatch size 12
minibatch produced ->  (12, 412) (12, 1695) (12,) (12,) (12, 1, 412) (12,)
remembering minibatch
learning params
rewards:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
action shape torch.Size([12, 1695])
log probs 1  tensor([[ 3.6707, 12.7663, 12.0417,  ..., 11.6900,  1.6129,  5.3660],
        [ 4.2957, 12.2097, 12.8141,  ..., 12.6859,  2.4917,  5.9099],
        [12.8932, 12.6718, 11.1410,  ..., 12.8036,  3.1137,  5.9506],
        ...,
        [12.7320, 11.8573, 12.6354,  ..., 12.6792, 12.8806,  5.0172],
        [10.8128, 12.8516, 12.6692,  ..., 12.3870,  2.9087,  5.9509],
        [ 3.3280, 12.8215, 10.9601,  ...,  4.1044,  2.4813, 12.8522]],
       grad_fn=<SubBackward0>) tensor([[ 114.8686,  -11.2220,  -75.3326,  ...,   16.6038,   10.9379,
          -60.6878],
        [ 127.9157,  -11.2209,  -75.3297,  ...,   16.6000,  -42.3924,
          -58.7493],
        [ 189.2246,   43.9932,  -67.7754,  ...,  -13.5011,  -66.3152,
          -59.1732],
        ...,
        [ 151.2951,   52.7664,  -45.3934,  ...,   37.7435, -109.6590,
          -21.6526],
        [ 189.2279,   43.9949,  -67.7711,  ...,  -13.5020,  -77.1964,
          -57.9998],
        [   7.4179,   61.0364,   -0.2339,  ...,   70.6493,  -28.8734,
          -11.6282]])
log probs 2  tensor([[    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        ...,
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        [    nan,     nan, 11.0163,  ...,     nan,     nan,     nan]],
       grad_fn=<SubBackward0>) tensor([[ 114.8686,  -11.2220,  -75.3326,  ...,   16.6038,   10.9379,
          -60.6878],
        [ 127.9157,  -11.2209,  -75.3297,  ...,   16.6000,  -42.3924,
          -58.7493],
        [ 189.2246,   43.9932,  -67.7754,  ...,  -13.5011,  -66.3152,
          -59.1732],
        ...,
        [ 151.2951,   52.7664,  -45.3934,  ...,   37.7435, -109.6590,
          -21.6526],
        [ 189.2279,   43.9949,  -67.7711,  ...,  -13.5020,  -77.1964,
          -57.9998],
        [   7.4179,   61.0364,   -0.2339,  ...,   70.6493,  -28.8734,
          -11.6282]])
log probs 3  tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], grad_fn=<SumBackward1>) tensor([[ 114.8686,  -11.2220,  -75.3326,  ...,   16.6038,   10.9379,
          -60.6878],
        [ 127.9157,  -11.2209,  -75.3297,  ...,   16.6000,  -42.3924,
          -58.7493],
        [ 189.2246,   43.9932,  -67.7754,  ...,  -13.5011,  -66.3152,
          -59.1732],
        ...,
        [ 151.2951,   52.7664,  -45.3934,  ...,   37.7435, -109.6590,
          -21.6526],
        [ 189.2279,   43.9949,  -67.7711,  ...,  -13.5020,  -77.1964,
          -57.9998],
        [   7.4179,   61.0364,   -0.2339,  ...,   70.6493,  -28.8734,
          -11.6282]])
value vs value target tensor([-0.0120, -0.0120, -0.0630, -0.0120, -0.0120, -0.0120, -0.0684, -0.0120,
        -0.0120, -0.0429, -0.0630, -0.0684], grad_fn=<ViewBackward>) tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       grad_fn=<SubBackward0>)
critic value tensor([-11.7521, -11.8906, -14.7859,  -5.1859,  -7.4745,  -8.7962, -12.7349,
        -10.2020, -15.6094, -24.2081, -15.9125, -11.7334],
       grad_fn=<ViewBackward>) log_probs tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       grad_fn=<ViewBackward>)
action shape torch.Size([12, 1695])
log probs 1  tensor([[ 4.3030, 12.8652, 12.5231,  ..., 12.8215,  2.5501,  5.0057],
        [ 3.3262, 11.2920, 12.8819,  ..., 12.0159,  2.4511,  1.6258],
        [12.8682, 12.1993, 12.7625,  ..., 12.5492,  3.0177,  5.8494],
        ...,
        [12.8903, 12.5847, 12.8935,  ..., 12.8654, 11.9260,  4.9485],
        [11.8840, 12.8956,  9.4868,  ..., 12.1648,  2.8708,  5.0772],
        [ 1.0729, 12.2511, 12.5226,  ...,  4.0592,  2.3925, 12.7378]],
       grad_fn=<SubBackward0>) tensor([[ 122.2411,  -11.2233,  -75.3289,  ...,   16.6018,  -66.5850,
          -61.2406],
        [ 112.5752,  -11.2198,  -75.3307,  ...,   16.5989,  -37.1555,
          -64.1385],
        [ 189.2241,   43.9924,  -67.7713,  ...,  -13.4989,  -72.3796,
          -59.5326],
        ...,
        [ 151.2959,   52.7675,  -45.3920,  ...,   37.7451, -109.6616,
          -22.2426],
        [ 189.2269,   43.9944,  -67.7678,  ...,  -13.4983,  -78.6236,
          -60.8456],
        [  -3.5698,   61.0338,   -0.2291,  ...,   68.0219,  -38.7070,
          -11.6287]], grad_fn=<MulBackward0>)
log probs 2  tensor([[    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        ...,
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        [    nan,     nan, 12.5765,  ...,     nan,     nan,     nan]],
       grad_fn=<SubBackward0>) tensor([[ 122.2411,  -11.2233,  -75.3289,  ...,   16.6018,  -66.5850,
          -61.2406],
        [ 112.5752,  -11.2198,  -75.3307,  ...,   16.5989,  -37.1555,
          -64.1385],
        [ 189.2241,   43.9924,  -67.7713,  ...,  -13.4989,  -72.3796,
          -59.5326],
        ...,
        [ 151.2959,   52.7675,  -45.3920,  ...,   37.7451, -109.6616,
          -22.2426],
        [ 189.2269,   43.9944,  -67.7678,  ...,  -13.4983,  -78.6236,
          -60.8456],
        [  -3.5698,   61.0338,   -0.2291,  ...,   68.0219,  -38.7070,
          -11.6287]], grad_fn=<MulBackward0>)
log probs 3  tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], grad_fn=<SumBackward1>) tensor([[ 122.2411,  -11.2233,  -75.3289,  ...,   16.6018,  -66.5850,
          -61.2406],
        [ 112.5752,  -11.2198,  -75.3307,  ...,   16.5989,  -37.1555,
          -64.1385],
        [ 189.2241,   43.9924,  -67.7713,  ...,  -13.4989,  -72.3796,
          -59.5326],
        ...,
        [ 151.2959,   52.7675,  -45.3920,  ...,   37.7451, -109.6616,
          -22.2426],
        [ 189.2269,   43.9944,  -67.7678,  ...,  -13.4983,  -78.6236,
          -60.8456],
        [  -3.5698,   61.0338,   -0.2291,  ...,   68.0219,  -38.7070,
          -11.6287]], grad_fn=<MulBackward0>)
q1_old_policy, q_hat tensor([0.2811, 0.2811, 0.2950, 0.2811, 0.2811, 0.2811, 0.4512, 0.2811, 0.2811,
        0.4444, 0.2950, 0.4512], grad_fn=<ViewBackward>) tensor([1.9575, 1.9575, 1.9881, 1.9575, 1.9575, 1.9575, 1.9681, 1.9575, 1.9575,
        1.9323, 1.9881, 1.9681], grad_fn=<AddBackward0>)
critic loss 1 and 2 tensor(1.3426, grad_fn=<MulBackward0>) tensor(5.9378, grad_fn=<MulBackward0>)
critic_losesss:  tensor(7.2803, grad_fn=<AddBackward0>)
---------------------MINIBATCH 2 -----------------
appending prev_obs with size: 4
running game for steps:  4
observation:  [[0 0 1 ... 1 0 0]
 [0 0 1 ... 1 0 0]
 [0 0 1 ... 1 0 0]]
action shape torch.Size([1, 3, 1695])
log probs 1  tensor([[[ 4.7388, 12.4203, 11.3310,  ..., 12.1160, 12.7946,  7.7499],
         [ 5.0661, 12.8111, 12.8740,  ..., 11.9541, 12.6148,  7.7574],
         [ 4.7390, 12.3794, 12.6616,  ..., 12.8110, 12.8708,  7.8349]]],
       grad_fn=<SubBackward0>) tensor([[[ 1.1682e+02, -7.1796e+01, -7.5117e+01,  ..., -1.5046e+00,
          -1.3474e+01,  9.3610e-02],
         [ 1.1113e+02, -7.1795e+01, -7.5121e+01,  ..., -1.5048e+00,
          -1.3476e+01,  9.8566e-02],
         [ 1.1682e+02, -7.1792e+01, -7.5122e+01,  ..., -1.5032e+00,
          -1.3475e+01,  1.9362e-01]]])
log probs 2  tensor([[[   nan,    nan,    nan,  ...,    nan,    nan, 7.7587],
         [   nan,    nan,    nan,  ...,    nan,    nan, 7.7672],
         [   nan,    nan,    nan,  ...,    nan,    nan, 7.8731]]],
       grad_fn=<SubBackward0>) tensor([[[ 1.1682e+02, -7.1796e+01, -7.5117e+01,  ..., -1.5046e+00,
          -1.3474e+01,  9.3610e-02],
         [ 1.1113e+02, -7.1795e+01, -7.5121e+01,  ..., -1.5048e+00,
          -1.3476e+01,  9.8566e-02],
         [ 1.1682e+02, -7.1792e+01, -7.5122e+01,  ..., -1.5032e+00,
          -1.3475e+01,  1.9362e-01]]])
log probs 3  tensor([[[    nan,     nan,     nan,  ...,     nan,     nan, 23.3990]]],
       grad_fn=<SumBackward1>) tensor([[[ 1.1682e+02, -7.1796e+01, -7.5117e+01,  ..., -1.5046e+00,
          -1.3474e+01,  9.3610e-02],
         [ 1.1113e+02, -7.1795e+01, -7.5121e+01,  ..., -1.5048e+00,
          -1.3476e+01,  9.8566e-02],
         [ 1.1682e+02, -7.1792e+01, -7.5122e+01,  ..., -1.5032e+00,
          -1.3475e+01,  1.9362e-01]]])
possible_actions_probablities [[      -inf       -inf       -inf ...       -inf       -inf 0.09361023]
 [      -inf       -inf       -inf ...       -inf       -inf 0.09856597]
 [      -inf       -inf       -inf ...       -inf       -inf 0.19361867]]
actions taken:  [11 11 11]
rewards (array([0., 0., 0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0.]))
observation:  [[1 0 0 ... 1 0 0]
 [1 0 0 ... 1 0 0]
 [1 0 0 ... 1 0 0]]
action shape torch.Size([1, 3, 1695])
log probs 1  tensor([[[ 4.4320, 12.8959, 12.8682,  ..., 11.0180,  2.3514, 12.2742],
         [ 4.4469, 12.8596, 12.7277,  ..., 12.5922,  2.5012, 12.8879],
         [ 4.4188, 11.9260, 12.8244,  ..., 11.8330,  2.1480, 12.4801]]],
       grad_fn=<SubBackward0>) tensor([[[ 68.4521, -58.1474, -60.0170,  ...,   3.5020,  -6.4504,  19.8941],
         [ 69.6741, -58.1479, -60.0176,  ...,   3.5040, -74.3650,  19.8925],
         [ 71.7047, -58.1498, -60.0172,  ...,   3.5029,  -2.5114,  19.8938]]])
log probs 2  tensor([[[nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SubBackward0>) tensor([[[ 68.4521, -58.1474, -60.0170,  ...,   3.5020,  -6.4504,  19.8941],
         [ 69.6741, -58.1479, -60.0176,  ...,   3.5040, -74.3650,  19.8925],
         [ 71.7047, -58.1498, -60.0172,  ...,   3.5029,  -2.5114,  19.8938]]])
log probs 3  tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SumBackward1>) tensor([[[ 68.4521, -58.1474, -60.0170,  ...,   3.5020,  -6.4504,  19.8941],
         [ 69.6741, -58.1479, -60.0176,  ...,   3.5040, -74.3650,  19.8925],
         [ 71.7047, -58.1498, -60.0172,  ...,   3.5029,  -2.5114,  19.8938]]])
possible_actions_probablities [[       -inf        -inf        -inf ...        -inf        -inf
  19.89414024]
 [       -inf        -inf        -inf ...        -inf        -inf
  19.89247322]
 [       -inf        -inf        -inf ...        -inf        -inf
  19.89379692]]
actions taken:  [11 11 11]
rewards (array([0., 0., 0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0.]))
observation:  [[1 0 0 ... 1 0 0]
 [1 0 0 ... 1 0 0]
 [1 0 0 ... 1 0 0]]
action shape torch.Size([1, 3, 1695])
log probs 1  tensor([[[12.5935, 12.5019, 12.1038,  ..., 11.2929,  3.4436, 11.0338],
         [11.6609, 12.6078, 12.7890,  ..., 12.7212,  0.3854, 11.3605],
         [12.6300, 12.4007, 10.8280,  ..., 12.8601,  2.3826, 12.8871]]],
       grad_fn=<SubBackward0>) tensor([[[  95.7239,   -3.4422,  -49.7701,  ...,   19.6096,  -64.4906,
            12.1441],
         [  95.7279,   -3.4394,  -49.7714,  ...,   19.6136, -121.9440,
            12.1444],
         [  95.7240,   -3.4424,  -49.7757,  ...,   19.6131,  -39.9283,
            12.1476]]])
log probs 2  tensor([[[nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SubBackward0>) tensor([[[  95.7239,   -3.4422,  -49.7701,  ...,   19.6096,  -64.4906,
            12.1441],
         [  95.7279,   -3.4394,  -49.7714,  ...,   19.6136, -121.9440,
            12.1444],
         [  95.7240,   -3.4424,  -49.7757,  ...,   19.6131,  -39.9283,
            12.1476]]])
log probs 3  tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SumBackward1>) tensor([[[  95.7239,   -3.4422,  -49.7701,  ...,   19.6096,  -64.4906,
            12.1441],
         [  95.7279,   -3.4394,  -49.7714,  ...,   19.6136, -121.9440,
            12.1444],
         [  95.7240,   -3.4424,  -49.7757,  ...,   19.6131,  -39.9283,
            12.1476]]])
possible_actions_probablities [[       -inf        -inf        -inf ...        -inf        -inf
  12.14410973]
 [       -inf        -inf        -inf ...        -inf        -inf
  12.14441013]
 [       -inf        -inf        -inf ...        -inf        -inf
  12.14761353]]
actions taken:  [1694 1694 1694]
rewards (array([0., 0., 0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0.]))
observation:  [[0 1 0 ... 0 1 0]
 [0 1 0 ... 0 1 0]
 [0 1 0 ... 0 1 0]]
action shape torch.Size([1, 3, 1695])
log probs 1  tensor([[[ 1.4271, 11.7881, 12.8771,  ..., 12.8416,  1.8936, 12.6291],
         [ 2.0941, 12.4602,  9.8372,  ..., 12.8201,  2.0047, 10.1071],
         [ 1.0040, 11.9076, 12.8857,  ..., 12.4902,  1.0537, 12.8665]]],
       grad_fn=<SubBackward0>) tensor([[[ -30.5974,    1.9681,  -50.5067,  ...,   98.1517,   59.7192,
            -0.6889],
         [  20.3563,    1.9671,  -50.5029,  ...,   98.1518,   43.6608,
            -0.6836],
         [ -51.4862,    1.9632,  -50.5068,  ...,   98.1496, -113.2067,
            -0.6880]]])
log probs 2  tensor([[[    nan,     nan,     nan,  ...,     nan,     nan, 13.2726],
         [    nan,     nan,     nan,  ...,     nan,     nan, 10.7369],
         [    nan,     nan,     nan,  ...,     nan,     nan, 13.5078]]],
       grad_fn=<SubBackward0>) tensor([[[ -30.5974,    1.9681,  -50.5067,  ...,   98.1517,   59.7192,
            -0.6889],
         [  20.3563,    1.9671,  -50.5029,  ...,   98.1518,   43.6608,
            -0.6836],
         [ -51.4862,    1.9632,  -50.5068,  ...,   98.1496, -113.2067,
            -0.6880]]])
log probs 3  tensor([[[    nan,     nan,     nan,  ...,     nan,     nan, 37.5173]]],
       grad_fn=<SumBackward1>) tensor([[[ -30.5974,    1.9681,  -50.5067,  ...,   98.1517,   59.7192,
            -0.6889],
         [  20.3563,    1.9671,  -50.5029,  ...,   98.1518,   43.6608,
            -0.6836],
         [ -51.4862,    1.9632,  -50.5068,  ...,   98.1496, -113.2067,
            -0.6880]]])
possible_actions_probablities [[       -inf        -inf        -inf ...        -inf        -inf
  -0.68885213]
 [       -inf        -inf        -inf ...        -inf        -inf
  -0.68360889]
 [       -inf        -inf        -inf ...        -inf        -inf
  -0.68802804]]
actions taken:  [1694 1694 1694]
rewards (array([0., 0., 0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0.]))
end length:  4
before cutting:  (4, 3, 412)
after cutting:  (4, 3, 412)
minibatch size 12
minibatch produced ->  (12, 412) (12, 1695) (12,) (12,) (12, 1, 412) (12,)
remembering minibatch
learning params
rewards:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
action shape torch.Size([12, 1695])
log probs 1  tensor([[ 2.2534, 12.1411, 12.7775,  ..., 11.4410,  2.0167, 12.8964],
        [ 2.2296, 11.8931, 11.8787,  ..., 12.8244,  1.9266, 12.0722],
        [ 3.4598, 12.8952, 11.7301,  ..., 12.6500,  2.1762,  3.4980],
        ...,
        [11.8734, 11.7696, 10.8014,  ..., 12.8905, 12.8831,  3.7663],
        [ 3.4378, 12.0611, 12.0023,  ...,  2.6649,  2.0642, 12.5365],
        [ 3.4269, 12.5876, 12.7417,  ...,  3.5650,  2.4075, 12.5637]],
       grad_fn=<SubBackward0>) tensor([[  55.9762,    1.9634,  -50.5062,  ...,   98.1483,  -30.3865,
           -0.6876],
        [  76.7323,    1.9631,  -50.5046,  ...,   98.1518,   55.4939,
           -0.6898],
        [ 102.8531,  -13.6126,  -74.2094,  ...,   19.6633,  -32.3516,
          -64.6319],
        ...,
        [ 142.9783,   59.5357,  -38.7249,  ...,   51.4933, -116.1169,
          -23.0040],
        [   4.8832,   63.2435,   12.6107,  ...,  107.8552,   40.1790,
           -2.8579],
        [   3.9454,   63.2470,   12.6094,  ...,   81.5628,  -25.6430,
           -2.8580]])
log probs 2  tensor([[    nan,     nan,     nan,  ...,     nan,     nan, 13.5365],
        [    nan,     nan,     nan,  ...,     nan,     nan, 12.7181],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        ...,
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],
       grad_fn=<SubBackward0>) tensor([[  55.9762,    1.9634,  -50.5062,  ...,   98.1483,  -30.3865,
           -0.6876],
        [  76.7323,    1.9631,  -50.5046,  ...,   98.1518,   55.4939,
           -0.6898],
        [ 102.8531,  -13.6126,  -74.2094,  ...,   19.6633,  -32.3516,
          -64.6319],
        ...,
        [ 142.9783,   59.5357,  -38.7249,  ...,   51.4933, -116.1169,
          -23.0040],
        [   4.8832,   63.2435,   12.6107,  ...,  107.8552,   40.1790,
           -2.8579],
        [   3.9454,   63.2470,   12.6094,  ...,   81.5628,  -25.6430,
           -2.8580]])
log probs 3  tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], grad_fn=<SumBackward1>) tensor([[  55.9762,    1.9634,  -50.5062,  ...,   98.1483,  -30.3865,
           -0.6876],
        [  76.7323,    1.9631,  -50.5046,  ...,   98.1518,   55.4939,
           -0.6898],
        [ 102.8531,  -13.6126,  -74.2094,  ...,   19.6633,  -32.3516,
          -64.6319],
        ...,
        [ 142.9783,   59.5357,  -38.7249,  ...,   51.4933, -116.1169,
          -23.0040],
        [   4.8832,   63.2435,   12.6107,  ...,  107.8552,   40.1790,
           -2.8579],
        [   3.9454,   63.2470,   12.6094,  ...,   81.5628,  -25.6430,
           -2.8580]])
value vs value target tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       grad_fn=<ViewBackward>) tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       grad_fn=<SubBackward0>)
critic value tensor([-12.9499,  -2.9810,  -9.0535, -12.2304,  -6.2437, -13.8282, -12.5675,
        -12.2209,  -1.9918, -12.9041, -11.7406,  -6.3212],
       grad_fn=<ViewBackward>) log_probs tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       grad_fn=<ViewBackward>)
action shape torch.Size([12, 1695])
log probs 1  tensor([[ 2.1467, 12.8670, 12.2447,  ..., 12.7299,  2.1009, 12.8517],
        [ 0.7472, 12.8731, 12.3090,  ..., 12.2037,  1.4478, 12.7530],
        [ 3.3605, 12.5592, 12.3794,  ..., 12.6847,  2.6132,  3.4660],
        ...,
        [12.7320, 12.8922, 12.4767,  ..., 12.8716, 12.8952,  3.7331],
        [ 3.3483, 11.6609, 12.8761,  ...,  3.5145,  1.4128, 12.8959],
        [ 3.4246, 12.2297, 12.5832,  ...,  1.2961,  2.4063, 12.7171]],
       grad_fn=<SubBackward0>) tensor([[  93.6042,    1.9659,  -50.5090,  ...,   98.1502,   18.5341,
           -0.6881],
        [ 183.0214,    1.9651,  -50.5052,  ...,   98.1532,   99.7154,
           -0.6885],
        [ 117.6258,  -13.6113,  -74.2051,  ...,   19.6632,  -55.6334,
          -82.9030],
        ...,
        [ 142.9797,   59.5381,  -38.7229,  ...,   51.4939, -116.1173,
          -16.4906],
        [  19.7645,   63.2430,   12.6081,  ...,   88.3738,   73.5954,
           -2.8593],
        [  15.4756,   63.2437,   12.6098,  ...,  122.8581,  -25.9198,
           -2.8604]], grad_fn=<MulBackward0>)
log probs 2  tensor([[    nan,     nan,     nan,  ...,     nan,     nan, 13.4932],
        [    nan,     nan,     nan,  ...,     nan,     nan, 13.3955],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        ...,
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],
       grad_fn=<SubBackward0>) tensor([[  93.6042,    1.9659,  -50.5090,  ...,   98.1502,   18.5341,
           -0.6881],
        [ 183.0214,    1.9651,  -50.5052,  ...,   98.1532,   99.7154,
           -0.6885],
        [ 117.6258,  -13.6113,  -74.2051,  ...,   19.6632,  -55.6334,
          -82.9030],
        ...,
        [ 142.9797,   59.5381,  -38.7229,  ...,   51.4939, -116.1173,
          -16.4906],
        [  19.7645,   63.2430,   12.6081,  ...,   88.3738,   73.5954,
           -2.8593],
        [  15.4756,   63.2437,   12.6098,  ...,  122.8581,  -25.9198,
           -2.8604]], grad_fn=<MulBackward0>)
log probs 3  tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], grad_fn=<SumBackward1>) tensor([[  93.6042,    1.9659,  -50.5090,  ...,   98.1502,   18.5341,
           -0.6881],
        [ 183.0214,    1.9651,  -50.5052,  ...,   98.1532,   99.7154,
           -0.6885],
        [ 117.6258,  -13.6113,  -74.2051,  ...,   19.6632,  -55.6334,
          -82.9030],
        ...,
        [ 142.9797,   59.5381,  -38.7229,  ...,   51.4939, -116.1173,
          -16.4906],
        [  19.7645,   63.2430,   12.6081,  ...,   88.3738,   73.5954,
           -2.8593],
        [  15.4756,   63.2437,   12.6098,  ...,  122.8581,  -25.9198,
           -2.8604]], grad_fn=<MulBackward0>)
q1_old_policy, q_hat tensor([994.5104, 994.5104,   4.0936,   6.4537,   4.0936,   4.1077, 994.5052,
          4.0936,   6.4383,   6.4516,   6.4537,   6.4537],
       grad_fn=<ViewBackward>) tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       grad_fn=<AddBackward0>)
critic loss 1 and 2 tensor(nan, grad_fn=<MulBackward0>) tensor(nan, grad_fn=<MulBackward0>)
critic_losesss:  tensor(nan, grad_fn=<AddBackward0>)
---------------------MINIBATCH 3 -----------------
appending prev_obs with size: 0
running game for steps:  4
observation:  [[0 0 1 ... 0 0 1]
 [0 0 1 ... 0 0 1]
 [0 0 1 ... 0 0 1]]
action shape torch.Size([1, 3, 1695])
log probs 1  tensor([[[ 3.0572, 12.8682, 12.6692,  ..., 12.6401,  2.8701, 12.8966],
         [ 2.7302, 12.7757, 12.8476,  ..., 12.8722,  3.4915, 12.7579],
         [ 3.0728, 12.5964, 12.8907,  ...,  8.5468,  3.4394, 12.8867]]],
       grad_fn=<SubBackward0>) tensor([[[ 136.0629, -113.5917,  -96.8029,  ...,    4.8703,  -38.1361,
             7.5872],
         [ 119.7471, -113.5905,  -96.8012,  ...,    4.8687,  -14.5755,
             7.5881],
         [ 154.1433, -113.5900,  -96.8016,  ...,    4.8641,   -8.5122,
             7.5870]]])
log probs 2  tensor([[[nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SubBackward0>) tensor([[[ 136.0629, -113.5917,  -96.8029,  ...,    4.8703,  -38.1361,
             7.5872],
         [ 119.7471, -113.5905,  -96.8012,  ...,    4.8687,  -14.5755,
             7.5881],
         [ 154.1433, -113.5900,  -96.8016,  ...,    4.8641,   -8.5122,
             7.5870]]])
log probs 3  tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SumBackward1>) tensor([[[ 136.0629, -113.5917,  -96.8029,  ...,    4.8703,  -38.1361,
             7.5872],
         [ 119.7471, -113.5905,  -96.8012,  ...,    4.8687,  -14.5755,
             7.5881],
         [ 154.1433, -113.5900,  -96.8016,  ...,    4.8641,   -8.5122,
             7.5870]]])
possible_actions_probablities [[      -inf       -inf       -inf ...       -inf       -inf 7.58723116]
 [      -inf       -inf       -inf ...       -inf       -inf 7.58811951]
 [      -inf       -inf       -inf ...       -inf       -inf 7.58698893]]
actions taken:  [1694 1694 1694]
rewards (array([0., 0., 0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0.]))
observation:  [[1 0 0 ... 0 0 0]
 [1 0 0 ... 0 0 0]
 [1 0 0 ... 0 0 0]]
action shape torch.Size([1, 3, 1695])
log probs 1  tensor([[[ 2.4736, 12.2081, 12.8682,  ..., 12.8966,  2.5865, 12.8747],
         [ 2.2880, 12.4311, 12.8855,  ..., 12.8362,  2.6136, 12.4873],
         [ 2.8293,  9.3789, 12.1860,  ..., 12.8718,  2.1795, 12.8562]]],
       grad_fn=<SubBackward0>) tensor([[[ 130.8400,  -63.7297, -126.3323,  ...,   22.8146,  -41.3142,
            11.0146],
         [  55.8429,  -63.7333, -126.3329,  ...,   22.8152,  -39.4106,
            11.0135],
         [  98.7012,  -63.7362, -126.3307,  ...,   22.8142,   30.7275,
            11.0145]]])
log probs 2  tensor([[[nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SubBackward0>) tensor([[[ 130.8400,  -63.7297, -126.3323,  ...,   22.8146,  -41.3142,
            11.0146],
         [  55.8429,  -63.7333, -126.3329,  ...,   22.8152,  -39.4106,
            11.0135],
         [  98.7012,  -63.7362, -126.3307,  ...,   22.8142,   30.7275,
            11.0145]]])
log probs 3  tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SumBackward1>) tensor([[[ 130.8400,  -63.7297, -126.3323,  ...,   22.8146,  -41.3142,
            11.0146],
         [  55.8429,  -63.7333, -126.3329,  ...,   22.8152,  -39.4106,
            11.0135],
         [  98.7012,  -63.7362, -126.3307,  ...,   22.8142,   30.7275,
            11.0145]]])
possible_actions_probablities [[ 130.83998108  -63.72968674 -126.33228302 ...          -inf
           -inf          -inf]
 [  55.84293747  -63.73330688 -126.33293152 ...          -inf
           -inf          -inf]
 [  98.70124817  -63.73616791 -126.33067322 ...          -inf
           -inf          -inf]]
actions taken:  [7 7 7]
rewards (array([0., 0., 0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0.]))
observation:  [[1 0 0 ... 1 0 0]
 [1 0 0 ... 1 0 0]
 [1 0 0 ... 1 0 0]]
action shape torch.Size([1, 3, 1695])
log probs 1  tensor([[[12.7933, 12.2362, 12.8944,  ..., 12.2845,  3.5574, 12.8964],
         [12.8230, 12.7071, 12.8251,  ..., 12.8840,  3.3266, 12.4810],
         [12.8299, 12.7489, 12.7167,  ..., 12.6520,  2.6615, 12.7712]]],
       grad_fn=<SubBackward0>) tensor([[[ 86.2388, -12.6845, -39.3310,  ...,  18.2472, -73.7453,   1.0627],
         [ 86.2390, -12.6854, -39.3303,  ...,  18.2493, -56.0503,   1.0611],
         [ 86.2402, -12.6855, -39.3319,  ...,  18.2502, -94.9420,   1.0618]]])
log probs 2  tensor([[[nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SubBackward0>) tensor([[[ 86.2388, -12.6845, -39.3310,  ...,  18.2472, -73.7453,   1.0627],
         [ 86.2390, -12.6854, -39.3303,  ...,  18.2493, -56.0503,   1.0611],
         [ 86.2402, -12.6855, -39.3319,  ...,  18.2502, -94.9420,   1.0618]]])
log probs 3  tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SumBackward1>) tensor([[[ 86.2388, -12.6845, -39.3310,  ...,  18.2472, -73.7453,   1.0627],
         [ 86.2390, -12.6854, -39.3303,  ...,  18.2493, -56.0503,   1.0611],
         [ 86.2402, -12.6855, -39.3319,  ...,  18.2502, -94.9420,   1.0618]]])
possible_actions_probablities [[      -inf       -inf       -inf ...       -inf       -inf 1.06266987]
 [      -inf       -inf       -inf ...       -inf       -inf 1.06109631]
 [      -inf       -inf       -inf ...       -inf       -inf 1.06179285]]
actions taken:  [11 11 11]
rewards (array([0., 0., 0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0.]))
observation:  [[0 1 0 ... 1 0 0]
 [0 1 0 ... 1 0 0]
 [0 1 0 ... 1 0 0]]
action shape torch.Size([1, 3, 1695])
log probs 1  tensor([[[ 1.5263,  2.9734, 12.7890,  ..., 10.8732,  2.1884, 12.6773],
         [ 1.8748,  2.9494, 12.5279,  ..., 12.8866,  2.3128, 12.1074],
         [ 1.8473,  2.8005, 12.2102,  ..., 12.6408,  2.3841, 10.8355]]],
       grad_fn=<SubBackward0>) tensor([[[-47.3461,  12.9310, -34.3304,  ..., 138.9868, -22.7600,   9.4382],
         [ 36.7441,  34.8362, -34.3282,  ..., 138.9900,  39.7581,   9.4414],
         [ 63.6712,  44.4505, -34.3277,  ..., 138.9914,  16.6461,   9.4359]]])
log probs 2  tensor([[[nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan],
         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SubBackward0>) tensor([[[-47.3461,  12.9310, -34.3304,  ..., 138.9868, -22.7600,   9.4382],
         [ 36.7441,  34.8362, -34.3282,  ..., 138.9900,  39.7581,   9.4414],
         [ 63.6712,  44.4505, -34.3277,  ..., 138.9914,  16.6461,   9.4359]]])
log probs 3  tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SumBackward1>) tensor([[[-47.3461,  12.9310, -34.3304,  ..., 138.9868, -22.7600,   9.4382],
         [ 36.7441,  34.8362, -34.3282,  ..., 138.9900,  39.7581,   9.4414],
         [ 63.6712,  44.4505, -34.3277,  ..., 138.9914,  16.6461,   9.4359]]])
possible_actions_probablities [[      -inf       -inf       -inf ...       -inf       -inf 9.43817711]
 [      -inf       -inf       -inf ...       -inf       -inf 9.44142914]
 [      -inf       -inf       -inf ...       -inf       -inf 9.43585968]]
actions taken:  [1694 1694 1694]
rewards (array([0., 0., 0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0.]))
end length:  0
before cutting:  (4, 3, 412)
after cutting:  (4, 3, 412)
minibatch size 12
minibatch produced ->  (12, 412) (12, 1695) (12,) (12,) (12, 1, 412) (12,)
remembering minibatch
learning params
rewards:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
action shape torch.Size([12, 1695])
log probs 1  tensor([[ 2.9367, 12.8965, 11.2576,  ..., 12.2227,  2.6777, 11.6106],
        [ 1.6883, 12.8408, 12.8956,  ..., 12.4130,  1.8479, 12.6358],
        [ 3.7441, 11.7808, 12.5818,  ..., 12.4077,  3.0590, 12.7886],
        ...,
        [ 3.0838, 11.1340, 11.6726,  ..., 11.7169,  3.4275, 11.6491],
        [11.5039, 12.1317, 12.4489,  ..., 12.8509,  2.8178,  6.7267],
        [ 2.7056, 12.2452, 12.4275,  ..., 12.5978,  2.8798,  2.6849]],
       grad_fn=<SubBackward0>) tensor([[  47.4215,  -56.5900,  -58.0351,  ...,    3.6793,  -20.4113,
           15.7245],
        [ 139.4471,    4.6399,  -45.5973,  ...,   98.9904,  -50.7312,
            3.2781],
        [  69.5618,  -56.5926,  -58.0307,  ...,    3.6830,  -51.8927,
           15.7210],
        ...,
        [ 152.8486, -113.5882,  -96.8044,  ...,    4.8717,   -7.7971,
            7.5899],
        [ 179.7885,   43.3309,  -54.1104,  ...,    7.2614,  -37.4423,
          -60.7623],
        [ 137.3072,  -10.0528,  -73.4294,  ...,   20.5775,  -82.1627,
          -53.4953]])
log probs 2  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<SubBackward0>) tensor([[  47.4215,  -56.5900,  -58.0351,  ...,    3.6793,  -20.4113,
           15.7245],
        [ 139.4471,    4.6399,  -45.5973,  ...,   98.9904,  -50.7312,
            3.2781],
        [  69.5618,  -56.5926,  -58.0307,  ...,    3.6830,  -51.8927,
           15.7210],
        ...,
        [ 152.8486, -113.5882,  -96.8044,  ...,    4.8717,   -7.7971,
            7.5899],
        [ 179.7885,   43.3309,  -54.1104,  ...,    7.2614,  -37.4423,
          -60.7623],
        [ 137.3072,  -10.0528,  -73.4294,  ...,   20.5775,  -82.1627,
          -53.4953]])
log probs 3  tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], grad_fn=<SumBackward1>) tensor([[  47.4215,  -56.5900,  -58.0351,  ...,    3.6793,  -20.4113,
           15.7245],
        [ 139.4471,    4.6399,  -45.5973,  ...,   98.9904,  -50.7312,
            3.2781],
        [  69.5618,  -56.5926,  -58.0307,  ...,    3.6830,  -51.8927,
           15.7210],
        ...,
        [ 152.8486, -113.5882,  -96.8044,  ...,    4.8717,   -7.7971,
            7.5899],
        [ 179.7885,   43.3309,  -54.1104,  ...,    7.2614,  -37.4423,
          -60.7623],
        [ 137.3072,  -10.0528,  -73.4294,  ...,   20.5775,  -82.1627,
          -53.4953]])
value vs value target tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       grad_fn=<ViewBackward>) tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       grad_fn=<SubBackward0>)
critic value tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       grad_fn=<ViewBackward>) log_probs tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       grad_fn=<ViewBackward>)
action shape torch.Size([12, 1695])
log probs 1  tensor([[ 3.6762, 12.8966, 12.2211,  ..., 10.1201,  1.0125, 12.3029],
        [ 2.1268, 12.8704, 12.8816,  ..., 12.2886,  1.6678, 12.7701],
        [ 2.6726, 12.3870, 11.5532,  ..., 12.7961,  2.0982, 11.9759],
        ...,
        [ 2.3780, 11.9466, 12.8956,  ..., 12.8962,  3.4324, 12.8771],
        [12.6565, 12.0659, 12.8663,  ...,  9.9919,  1.0945,  6.8466],
        [ 2.4100, 12.6940, 12.8964,  ..., 12.1386,  1.8630,  1.2420]],
       grad_fn=<SubBackward0>) tensor([[  73.8131,  -56.5901,  -58.0340,  ...,    3.6773, -111.8941,
           15.7236],
        [  71.1419,    4.6389,  -45.5975,  ...,   98.9906,  -71.6223,
            3.2777],
        [  44.3675,  -56.5918,  -58.0348,  ...,    3.6821,   -4.3387,
           15.7194],
        ...,
        [ 109.6070, -113.5890,  -96.8018,  ...,    4.8691,   -8.0822,
            7.5869],
        [ 179.7845,   43.3352,  -54.1084,  ...,    7.2579,    4.3032,
          -61.6842],
        [  76.5738,  -10.0520,  -73.4310,  ...,   20.5741, -139.7501,
         -137.2468]], grad_fn=<MulBackward0>)
log probs 2  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<SubBackward0>) tensor([[  73.8131,  -56.5901,  -58.0340,  ...,    3.6773, -111.8941,
           15.7236],
        [  71.1419,    4.6389,  -45.5975,  ...,   98.9906,  -71.6223,
            3.2777],
        [  44.3675,  -56.5918,  -58.0348,  ...,    3.6821,   -4.3387,
           15.7194],
        ...,
        [ 109.6070, -113.5890,  -96.8018,  ...,    4.8691,   -8.0822,
            7.5869],
        [ 179.7845,   43.3352,  -54.1084,  ...,    7.2579,    4.3032,
          -61.6842],
        [  76.5738,  -10.0520,  -73.4310,  ...,   20.5741, -139.7501,
         -137.2468]], grad_fn=<MulBackward0>)
log probs 3  tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], grad_fn=<SumBackward1>) tensor([[  73.8131,  -56.5901,  -58.0340,  ...,    3.6773, -111.8941,
           15.7236],
        [  71.1419,    4.6389,  -45.5975,  ...,   98.9906,  -71.6223,
            3.2777],
        [  44.3675,  -56.5918,  -58.0348,  ...,    3.6821,   -4.3387,
           15.7194],
        ...,
        [ 109.6070, -113.5890,  -96.8018,  ...,    4.8691,   -8.0822,
            7.5869],
        [ 179.7845,   43.3352,  -54.1084,  ...,    7.2579,    4.3032,
          -61.6842],
        [  76.5738,  -10.0520,  -73.4310,  ...,   20.5741, -139.7501,
         -137.2468]], grad_fn=<MulBackward0>)
q1_old_policy, q_hat tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       grad_fn=<ViewBackward>) tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       grad_fn=<AddBackward0>)
critic loss 1 and 2 tensor(nan, grad_fn=<MulBackward0>) tensor(nan, grad_fn=<MulBackward0>)
critic_losesss:  tensor(nan, grad_fn=<AddBackward0>)
---------------------MINIBATCH 4 -----------------
appending prev_obs with size: 4
running game for steps:  4
observation:  [[0 0 1 ... 0 1 0]
 [0 0 1 ... 0 1 0]
 [0 0 1 ... 0 1 0]]
